{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from torch.nn.functional import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = 'C:/Users/sushl/Desktop/deep learning by stanford/synthetic image feature detection/synthetic-image-feature-detection-using-deep-learning/dataset/output'\n",
    "L = os.listdir(dataset_location)\n",
    "L.sort()\n",
    "img_path = []\n",
    "for i in range(int(len(L))):\n",
    "    img_path.append(dataset_location +\"/\"+ L[i])\n",
    "dataframe = {\"path\":img_path}\n",
    "df = pd.DataFrame(dataframe)\n",
    "df.to_csv(\"label.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89757</th>\n",
       "      <td>89757</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89758</th>\n",
       "      <td>89758</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89759</th>\n",
       "      <td>89759</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89760</th>\n",
       "      <td>89760</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89761</th>\n",
       "      <td>89761</td>\n",
       "      <td>C:/Users/sushl/Desktop/deep learning by stanfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89762 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               path\n",
       "0               0  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "1               1  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "2               2  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "3               3  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "4               4  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "...           ...                                                ...\n",
       "89757       89757  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "89758       89758  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "89759       89759  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "89760       89760  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "89761       89761  C:/Users/sushl/Desktop/deep learning by stanfo...\n",
       "\n",
       "[89762 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"label.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = 'C:/Users/sushl/Desktop/deep learning by stanford/synthetic image feature detection/synthetic-image-feature-detection-using-deep-learning/dataset/New folder'\n",
    "L = os.listdir(dataset_location)\n",
    "L.sort()\n",
    "img_path = []\n",
    "for i in range(int(len(L))):\n",
    "    img_path.append(dataset_location +\"/\"+ L[i])\n",
    "dataframe = {\"path\":img_path}\n",
    "df = pd.DataFrame(dataframe)\n",
    "df.to_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file,transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 1]\n",
    "        image = read_image(img_path)\n",
    "        img = cv.imread(img_path,0)\n",
    "        image = image/255\n",
    "        #print(image.dtype)\n",
    "        gray = np.float32(img)\n",
    "        dst = cv.cornerHarris(gray,2,3,0.04)\n",
    "        dst = dst/(dst.max()-dst.min()+0.00001)\n",
    "        x1 = np.where(dst > 0.05)[0]\n",
    "        y1 = np.where(dst > 0.05)[1]\n",
    "        n = len(x1)\n",
    "        #print(n)\n",
    "        label12 = np.stack((x1, y1), axis = 1)\n",
    "        blur = cv.getGaussianKernel(19,4)\n",
    "        blur = (blur + blur.T)/2\n",
    "        blur = blur/(blur.max()-blur.min())\n",
    "        label_img = np.zeros(img.shape)\n",
    "        for k in range(len(label12)):\n",
    "            label_img[label12[k,1]-10:label12[k,1]+9,label12[k,0]-10:label12[k,0]+9] = blur*255\n",
    "        #label = Image.fromarray(np.uint8(cm.gist_earth(label_img)*255))\n",
    "        label_img = cv.GaussianBlur(label_img,(11,11),0)\n",
    "        label = torch.from_numpy(label_img.T.reshape(1,200,200))\n",
    "        label = label/255\n",
    "        #print(label_img.)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = (image,label)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomImageDataset(\n",
    "    annotations_file= \"label.csv\",\n",
    "    transform=transforms.Compose([transforms.Resize((128,128))]),\n",
    "    target_transform=transforms.Compose([transforms.Resize((128,128))])\n",
    ")\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_labels.shape\n",
    "\n",
    "test_data = CustomImageDataset(\n",
    "    annotations_file= 'test.csv',\n",
    "    transform=transforms.Compose([transforms.Resize((128,128))]),\n",
    "    target_transform=transforms.Compose([transforms.Resize((128,128))])\n",
    ")\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    plt.imshow(test_features[i][0].numpy())\n",
    "    plt.figure()\n",
    "    plt.imshow(test_labels[i][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.convT1 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.convT2 = nn.Conv2d(32, 16, kernel_size=1, stride=1, padding=0)\n",
    "        self.convT3 = nn.Conv2d(16, 8, kernel_size=1, stride=1, padding=0)\n",
    "        self.convT4 = nn.Conv2d(8, 1, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.mp = nn.MaxPool2d(2, 2)\n",
    "        self.mup = nn.MaxUnpool2d(2,2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(8,8,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(8,8,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(8,8,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(16,16,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16,16,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16,16,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(32,32,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32,32,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32,32,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64,64,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64,64,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "        self.decoder1=nn.Sequential(\n",
    "            nn.ConvTranspose2d(64,64,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64,64,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64,64,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "        self.decoder2=nn.Sequential(\n",
    "            nn.ConvTranspose2d(32,32,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32,32,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32,32,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "        self.decoder3=nn.Sequential(\n",
    "            nn.ConvTranspose2d(16,16,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16,16,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16,16,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "        self.decoder4=nn.Sequential(\n",
    "            nn.ConvTranspose2d(8,8,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(8,8,kernel_size = 3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(8,8,kernel_size = 3,stride=1,padding=1),\n",
    "        )\n",
    "    def forward(self, features):\n",
    "        x = self.encode(features.float())\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, features):\n",
    "        x = self.conv1(features.float()) #3 to 8\n",
    "        residual = x\n",
    "        x = self.encoder1(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.batchnorm1(x)\n",
    "\n",
    "        x = self.conv2(x) #8 to 16\n",
    "        residual = x\n",
    "        x = self.encoder2(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        residual = x #16 to 16\n",
    "        x = self.encoder2(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        residual = x #16 to 16\n",
    "        x = self.encoder2(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        x = self.conv3(x) #16 to 32\n",
    "        residual = x\n",
    "        x = self.encoder3(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        residual = x #32 to 32\n",
    "        x = self.encoder3(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        residual = x #32 to 32\n",
    "        x = self.encoder3(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        x = self.conv4(x) #32 to 64\n",
    "        residual = x\n",
    "        x = self.encoder4(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        \n",
    "        residual = x #64 to 64\n",
    "        x = self.encoder4(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        \n",
    "        residual = x #64 to 64\n",
    "        x = self.encoder4(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def decode(self, features):\n",
    "        #x = interpolate(features.float(), scale_factor=2)\n",
    "        residual = features.float() #64 to 64\n",
    "        x = self.decoder1(features.float())\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        \n",
    "        residual = x #64 to 64\n",
    "        x = self.decoder1(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm4(x)\n",
    "         \n",
    "        x = self.convT1(x) #64 to 32\n",
    "        x = interpolate(x, scale_factor=2)\n",
    "        residual = x\n",
    "        x = self.decoder2(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        residual = x #32 to 32\n",
    "        x = self.decoder2(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        residual = x #32 to 32\n",
    "        x = self.decoder2(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        x = self.convT2(x) #32 to 16\n",
    "        x = interpolate(x, scale_factor=2)\n",
    "        residual = x \n",
    "        x = self.decoder3(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        residual = x #16 to 16\n",
    "        x = self.decoder3(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        residual = x  #16 to 16\n",
    "        x = self.decoder3(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        x = self.convT3(x) #16 to 8\n",
    "        x = interpolate(x, scale_factor=2)\n",
    "        residual = x \n",
    "        x = self.decoder4(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        residual = x #8 to 8\n",
    "        x = self.decoder4(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        residual = x #8 to 8\n",
    "        x = self.decoder4(x)\n",
    "        x = 0.5*(x + residual)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        x = self.convT4(x) #8 to 1\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dummy = torch.ones(64,3,128,128).to(device)\n",
    "a = model(dummy)\n",
    "a.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "m = 0.9\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=m)\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.BCELoss()\n",
    "def loss_function(output, target):\n",
    "    #print(output.max())\n",
    "    #print(output.min())\n",
    "    \n",
    "    #exp_output = exp_output/torch.sum(exp_output)\n",
    "    \n",
    "    #print(exp_output.max())\n",
    "    #print(exp_output.min())\n",
    "    #plt.figure()\n",
    "    #plt.imshow(exp_output[0].cpu().detach().numpy().reshape(96,96,1))\n",
    "    #plt.colorbar()\n",
    "    #plt.show()\n",
    "    loss = (torch.sum(torch.sum((output*output - target*target)**2)))**(1/2) #+ (torch.mean(torch.sum((output*(1-target) - (1-target)*(1-target))**2)))**(1/2)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "config = dict (\n",
    "    learning_rate =lr,\n",
    "    momentum = m,\n",
    "    batchsize = 128,\n",
    "    architecture = \"similar to resnet\",\n",
    "    dataset_id = \"shape dataset\",\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"feature detection on different shapes\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "for epoch in range(4):\n",
    "    for batch, (xb, yb) in enumerate(train_dataloader):\n",
    "        #print(len(xb))\n",
    "        X, y = xb.to(device), yb.to(device)\n",
    "        #print(X.shape)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        #print(pred.shape,y.shape)\n",
    "        loss = loss_function(pred,y)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters():\n",
    "                p -= p.grad * lr\n",
    "            model.zero_grad()\n",
    "        wandb.log({\"train_loss\": loss.item(), \"epoch\": 4,\"lr\" : lr,})\n",
    "        if batch % 2 == 0:\n",
    "            loss, current = loss.item(), (batch)*len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{90000:>5d}]\")\n",
    "        if batch % 16 == 0:\n",
    "            plt.figure()\n",
    "            plt.imshow(pred[0].cpu().detach().numpy().reshape(128,128,1))\n",
    "            plt.colorbar()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(27):\n",
    "    plt.figure()\n",
    "    plt.imshow(pred[i].cpu().detach().numpy().reshape(128,128,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(model, 'features.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'features.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
